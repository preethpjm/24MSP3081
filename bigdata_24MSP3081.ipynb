{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYoDIdtjOs3v"
      },
      "outputs": [],
      "source": [
        "#DataFrame / SQL\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"BigDataAnalytics\").getOrCreate()\n",
        "df = spark.read.csv(\"employees.csv\", header=True, inferSchema=True)\n",
        "df.createOrReplaceTempView(\"employees\")\n",
        "result = df.filter(col(\"salary\") > 55000).select(\"name\")\n",
        "#result = spark.sql(\"SELECT name FROM employees WHERE salary > 55000\")\n",
        "result.show()\n",
        "\n",
        "#RDD\n",
        "rdd = spark.sparkContext.textFile(\"employees.csv\")\n",
        "header = rdd.first()\n",
        "data = rdd.filter(lambda line: line != header)\n",
        "parsed = data.map(lambda line: line.split(\",\")).map(lambda x: (x[1], int(x[3])))\n",
        "filtered = parsed.filter(lambda x: x[1] > 55000)\n",
        "filtered.collect()\n",
        "\n",
        "#Linear Regression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "df = spark.read.csv(\"experience_salary.csv\", header=True, inferSchema=True)\n",
        "vec_assembler = VectorAssembler(inputCols=[\"years_experience\"], outputCol=\"features\")\n",
        "data = vec_assembler.transform(df)\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"salary\")\n",
        "model = lr.fit(data)\n",
        "\n",
        "print(\"Coefficients:\", model.coefficients)\n",
        "print(\"Intercept:\", model.intercept)\n",
        "\n",
        "predict_df = spark.createDataFrame([[8]], [\"years_experience\"])\n",
        "predict_df = vec_assembler.transform(predict_df)\n",
        "prediction = model.transform(predict_df)\n",
        "prediction.select(\"prediction\").show()\n",
        "\n",
        "#SVM\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "\n",
        "df = spark.read.csv(\"svm_data.csv\", header=True, inferSchema=True)\n",
        "vec_assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\"], outputCol=\"features\")\n",
        "data = vec_assembler.transform(df)\n",
        "\n",
        "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\")\n",
        "model = svm.fit(data)\n",
        "\n",
        "print(\"Coefficients:\", model.coefficients)\n",
        "print(\"Intercept:\", model.intercept)\n",
        "\n",
        "predictions = model.transform(data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()\n",
        "\n",
        "#KMeans\n",
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "df = spark.read.csv(\"points.csv\", header=True, inferSchema=True)\n",
        "vec_assembler = VectorAssembler(inputCols=[\"x\", \"y\"], outputCol=\"features\")\n",
        "data = vec_assembler.transform(df)\n",
        "\n",
        "kmeans = KMeans(k=2, seed=1)\n",
        "model = kmeans.fit(data)\n",
        "\n",
        "print(\"Cluster Centers:\", model.clusterCenters())\n",
        "\n",
        "predictions = model.transform(data)\n",
        "predictions.select(\"x\", \"y\", \"prediction\").show()\n",
        "\n",
        "#Text Mining SVD\n",
        "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
        "from pyspark.mllib.linalg.distributed import RowMatrix\n",
        "\n",
        "df = spark.read.text(\"lsi_docs.txt\").toDF(\"text\")\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "words_data = tokenizer.transform(df)\n",
        "\n",
        "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
        "cv_model = cv.fit(words_data)\n",
        "vectorized_data = cv_model.transform(words_data)\n",
        "\n",
        "vectors_rdd = vectorized_data.select(\"features\").rdd.map(lambda row: row[0].toArray())\n",
        "row_matrix = RowMatrix(vectors_rdd)\n",
        "\n",
        "svd = row_matrix.computeSVD(2, computeU=True)\n",
        "\n",
        "print(\"Singular Values:\", svd.s)\n",
        "print(\"First 2 rows of U:\", svd.U.rows.take(2))"
      ]
    }
  ]
}